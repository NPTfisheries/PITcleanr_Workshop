---
title: "PITcleanr Workshop"
author:
  - Ryan N. Kinzer
  - Mike Ackerman
  - Kevin See
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::html_document2:
    theme: yeti
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    number_sections: yes
always_allow_html: yes
---

```{r, echo = FALSE, message = FALSE, warning = FALSE, results = "hide"}
# knitr options
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)

library(knitr)
library(here)
library(kableExtra)

api_key = '1AA5CF55-C98E-4001-96E4-1E96CEE1E806'

```


# Installation

If necessary, the `PITcleanr` package can be installed as an R package from GitHub by using Hadley Wickham's `devtools` package. Additional information on package installation can be found on the [website README](https://github.com/KevinSee/PITcleanr?tab=readme-ov-file#installation-instructions). 

```{r gh-installation, eval = FALSE}
# install PITcleanr, if necessary
install.packages("devtools")
library(devtools)
remotes::install_github("KevinSee/PITcleanr", 
                         build_vignettes = TRUE)

```


# Load Packages

Once `PITcleanr` is successfully installed, it can be loaded into the R session. In this workshop, we will also use functions from the following packages. Packages can be loaded using the `library()` function. For any packages not already installed, the `install.packages()` function can be used first.

```{r load-packages}
# E.g., for packages not installed:
# install.packages(c("tidyverse", "sf"))

# load necessary packages
library(PITcleanr)
library(tidyverse)
library(sf)
library(kableExtra)

```

# Query Data

## PTAGIS Site Information

### Interrogation Sites

`PITcleanr` can be used to query and download metadata for PTAGIS interrogation sites using the function `queryInterrogationMeta()`. The `site_code` argument can be used to specify sites; alternatively, set `site_code` to `NULL` to retrieve metadata for all sites.

```{r int-meta}
# interrogation site metadata
int_meta_KRS = queryInterrogationMeta(site_code = "KRS")
int_meta = queryInterrogationMeta(site_code = NULL)

# count active instream remote sites by organization
int_meta %>%
  filter(siteType == "Instream Remote Detection System",
         active) %>%
  count(operationsOrganizationCode) %>%
  ggplot(aes(x = operationsOrganizationCode, y = n)) +
    geom_col() + 
    coord_flip()

```

As an example, we can use the `int_meta` objects to map our interrogation sites using the `sf` package. State polygons are available in the `maps` package.

```{r int-map}
# plot location of interrogation sites
library(maps)

# get state boundaries
pnw = st_as_sf(map("state", 
                   region = c('ID', 'WA', 'OR'), 
                   plot = FALSE, 
                   fill = TRUE)) # get state boundaries

# create spatial feature object of IPTDS
int_sf <- int_meta %>% 
  filter(siteType == "Instream Remote Detection System",
         !is.na(longitude),
         !is.na(latitude)) %>%
  st_as_sf(coords = c('longitude', 'latitude'), 
           crs = 4326) # WGS84

ggplot() + 
  geom_sf(data = pnw) + 
  geom_sf(data = int_sf, aes(color = active))

```

`PITcleanr` also includes the function `queryInterrogationConfig()` function to query and download configuration metadata for PTAGIS interrogation sites. The configuration metadata contains information about individual antennas, transceivers, etc., including their arrangement. Similar to above, `site_code` can be set to `NULL` to get configuration metadata for all PTAGIS interrogation sites.

```{r int-config}
# configuration of an interrogation site
int_config <- queryInterrogationConfig(site_code = 'ZEN')

int_config %>%
  kable() %>%
  kable_styling(full_width = TRUE,
                bootstrap_options = 'striped')

```

### Mark/Recapture/Recovery Sites

A similar function exists to query and download metadata for PTAGIS mark-recapture-recovery (MRR) sites.

```{r mrr-meta}
# all MRR sites
mrr_meta <- queryMRRMeta(site = NULL)

head(mrr_meta, 3) %>%
  kable() %>%
  kable_styling(full_width = TRUE,
                bootstrap_options = "striped")

```

### All PTAGIS Sites

`PITcleanr` includes additional functions that can query interrogation and MRR sites together. The `queryPtagisMeta()` function is a wrapper function to download all INT and MRR sites at once. The `buildConfig()` function goes a step further and downloads all INT and MRR site metadata, plus INT site configuration information, and applies some formatting to combine all PTAGIS site metadata.

```{r all-ptagis-sites}
# wrapper to download all site meta
ptagis_meta <- queryPtagisMeta()

# wrapper to download site metadata and INT configuration data at once, and apply some formatting
config <- buildConfig(node_assign = "array",
                      array_suffix = "UD")

# number of unique sites in PTAGIS
n_distinct(config$site_code)

# the number of antennas in PTAGIS
nrow(config)

head(config, 9) %>%
  select(-site_description) %>% # remove site_description column for formatting
  kable() %>%
  kable_styling(full_width = TRUE,
                bootstrap_options = "striped")

```

Note that the `buildConfig()` column includes the arguments `node_assign` and `array_suffix`. The `node_assign` argument includes the options `c("array", "site", "antenna")` which allows the user to assign PIT tag arrays, entire sites, or individual antennas, respectively, which can be used as the scale for subsequent data prep and analysis. By default, observations are assigned to individual `"array"`s, and upstream and downstream arrays are assigned the suffixes "_U" and "_D", respectively. In the case of 3-span arrays, observations at the middle array are assigned to the upstream array. More on this later...


## PTAGIS Tag Data

### Test Tags

`PITcleanr` includes the function `queryTestTagSite()` which can be used to query and download the test tag history for one INT site for an entire calendar year, which can be useful for evaluating site performance.

```{r test-tag}
# check for timer tag to evaluate site operation
test_tag = queryTestTagSite(site_code = "ZEN", 
                            year = 2023, 
                            api_key = api_key)

test_tag %>%
  group_by(antenna_id, time_stamp, tag_code) %>%
  count() %>%
  ggplot(aes(x = time_stamp, y = n, colour = tag_code)) +
  geom_point() +
  facet_wrap(~antenna_id)

```

```{r tag-meta, eval = F, echo = F}
# not working
#queryTagMeta("3D9.1C2D929849") # not exported

```

### Complete Tag History

`PITcleanr` includes the function `queryCapHist()` to query and download the complete tag history for one tag from PTAGIS (via DART).

```{r complete-tag-history}
# query PTAGIS complete tag history for a single tag code; some examples
tagID <- "3D6.1D594D4AFA" # IR3, GOJ, BO1 -> IR5
tagID <- "3DD.003D494091" # GRA, IR1 -> IML

tag_cth = queryCapHist(ptagis_tag_code = tagID)

# view complete tag history
tag_cth

# example to summarise CTH
tag_cth %>%
  group_by(event_type_name, 
           event_site_code_value) %>%
  summarise(n_dets = n(),
            min_det = min(event_date_time_value),
            max_det = max(event_date_time_value)) %>%
  mutate(duration = difftime(max_det, min_det, units = "hours")) %>%
  kable() %>%
  kable_styling(full_width = TRUE,
            bootstrap_options = 'striped') 

```

Due to PTAGIS no longer providing queries for the mark event information for a given tag code, only observations after the mark event are returned.

```{r complete-tag-history-node, eval = FALSE, echo = FALSE}
# doesn't work - nothing is different from when config is not supplied
cth_node <- queryCapHist(ptagis_tag_code = tagID,
                         config = config,
                         include_mark = TRUE,
                         api_key = api_key)

glimpse(cth_node) %>%
  kable()

```

### Mark-Recovery-Recapture Files

If desired, the `queryMRRDataFile()` function can be used to query a raw MRR file for PTAGIS MRR sites. NOTE: only the latest, corrected, version of a MRR file is returned.

```{r MRR-single-file}
# MRR tag file summaries
mrr_file <- "NBD15065.TUM"
mrr_file <- "JSW-2022-175-001.xml"

mrr_data <- queryMRRDataFile(mrr_file)

# view mrr data file
mrr_data

# mrr_data %>%
#   filter(event_type == 'Mark') %>%
#   group_by(event_date, species_run_rear_type) %>%
#   count() %>%
#   ggplot(aes(x = event_date, y = n, fill = species_run_rear_type)) +
#   geom_col() +
#   labs(title = paste0(unique(mrr_data$release_site), ' : ', mrr_file))

# summary of injuries
mrr_data %>%
  group_by(species_run_rear_type, text_comments) %>%
  count() %>%
  ggplot(aes(x = text_comments, y = n, fill = species_run_rear_type)) +
  geom_col() +
  coord_flip() +
  labs(title = paste0(unique(mrr_data$release_site), ' : ', mrr_file))

```

Using the `map_df()` function, the user can use the `queryMRRDataFile()` function to iterate over multiple MRR tag files and combing them into a single data frame.

```{r MRR-multiple-files}
julian = str_pad(1:10, 3, pad = 0) # julian 001 - 010
yr = 2024                          # tagging year

# Imnaha smolt trap, first 10 days of 2024
mrr_files = paste0("IMN-", yr, "-", julian, "-NT1.xml")

mrr_data <- map_df(mrr_files,  # loop across files
             .f = queryMRRDataFile)

# view mrr data
mrr_data

# summarise new marks by day
mrr_data %>% 
  filter(event_type == 'Mark') %>%
  mutate(release_date = date(release_date)) %>%
  group_by(release_date, 
           species_run_rear_type) %>%
  count() %>%
  kable() %>%
  kable_styling(full_width = TRUE)

```

The user could combine mark data from `queryMRRDataFile()` and observations after the mark event from `queryCapHist()` into complete tag histories. However, the user may choose to read in a complete tag history that they've previously queried and downloaded from PTAGIS.


# PITcleanr Workflow

PTAGIS contains a record of each detection of every PIT tag, including the initial detection, or "mark", when the tag is implanted, detections on PIT-tag antennas, recaptures (e.g., at weirs), and recoveries (e.g., carcass surveys). It contains a record of every individual detection, which potentially means multiple records of a tag being detected on the same antenna over and over e.g., in the case that it is not moving. Therefore, querying PTAGIS for all these detections often leands to a wealth of data, which can be unwieldy for the user. `PITcleanr` aims to compress that data to a more manageable size, without losing any of the information contained in the dataset.

Here, we provide a typical workflow, starting with querying a tag list for a complete tag history in PTAGIS.

## Tag List

A tag list is typically a *.txt* file with one row per tag code, which makes it easy to upload to a PTAGIS query. For convenience, we've included one such file with `PITcleanr`, which contains tag IDs for Chinook salmon adults implanted with tags at Tumwater Dam in 2018. The following can be used to find the path to this example file. Alternatively, the user can provide the file path to their own tag list.

```{r tag-list}
# generate file path to example tag list in PITcleanr
tag_list = system.file("extdata", 
                       "TUM_chnk_tags_2018.txt", 
                       package = "PITcleanr",
                       mustWork = TRUE)

# or simple example to your own file on desktop
tag_list = "C:/Users/username/Desktop/my_tag_list.txt"

```

## Read Complete Tag History

Once the user has created their own tag list, or located this example one, they can go to [PTAGIS](https://www.ptagis.org/) to query the complete tag histories for those tags. Detailed instructions for querying complete tag histories for use in PITcleanr can be found [here](https://kevinsee.github.io/PITcleanr/articles/Prep_PIT_data.html#complete-capture-history). Briefly, the following fields or attributes are required:

* Tag
* Event Site Code
* Event Date Time
* Antenna
* Antenna Group Configuration

And the following are highly recommended:

* Mark Species
* Mark Rear Type
* Event Type
* Event Site Type
* Event Release Site Code
* Event Release Date Time

Any other fields of interest to the user may be included as well.

For convenience, we've included an example complete tag history in `PITcleanr`, or you can provide the file path to your own complete tag history.

```{r ptagis-filepath}
# file path to the example CTH in PITcleanr
ptagis_file <- system.file("extdata", 
                          "TUM_chnk_cth_2018.csv",
                          package = "PITcleanr",
                          mustWork = TRUE)

```

The `PITcleanr` function `readCTH()` can then be used to read in your complete tag history. `readCTH()` also ensures that column names are consistent for subsequent `PITcleanr` functions.

```{r read-cth}
raw_ptagis = readCTH(ptagis_file,
                     file_type = "PTAGIS") %>%
  # filter for only detections after start of run year
  filter(event_date_time_value >= lubridate::ymd(20180301))

# number of detections
nrow(raw_ptagis)

# number of unique tags
dplyr::n_distinct(raw_ptagis$tag_code)

```

Note that `readCTH()` includes the argument `file_type` which can be used to import data from [Biomark's BioLogic](https://data3.biomark.com/accounts/login/?next=/#) ("Biologic_csv") database or data downloaded directly from the reader, in either a .log or .xlsx format ("raw"). These formats may be useful for smaller studies or studies outside the Columbia River Basin whose data may not be uploaded to PTAGIS. Perhaps more on this later...

## Quality Control

The `qcTagHistory()` function can be used to perform some basic quality control on the PTAGIS detections. Note it can be run on either the file path to the complete tag histories or the data frame returned by `readCTH()`. `qcTagHistory()` provides information on disowned and orphan tags and information on the various release groups included in the detections. More info can be found [here](https://kevinsee.github.io/PITcleanr/articles/Prep_PIT_data.html#quality-control).

```{r qc-data}
# complete tag history file
qc_detections = qcTagHistory(ptagis_file)

# complete tag history tibble from readCTH()
qc_detections = qcTagHistory(raw_ptagis)

# view QC results
qc_detections

```

## Parent-Child Table

```{r extract-sites}
sites_sf = extractSites(raw_ptagis,
                        as_sf = T,
                        min_date = "20180501")

# focus on sites within Wenatchee subbasin, and drop a few sites we don't care about
sites_sf = sites_sf %>%
  # all sites in Wenatchee have an rkm starting with 755
  filter(str_detect(rkm, "^754."),
         type != "MRR",
         site_code != "LWE") %>%
  mutate(across(site_code,
                ~ recode(.,
                         "TUF" = "TUM")))

```

```{r nhd-flowlines}
nhd_list = queryFlowlines(sites_sf = sites_sf,
                          root_site_code = "TUM",
                          min_strm_order = 2,
                          dwnstrm_sites = T,
                          dwn_min_stream_order_diff = 2)
#> Querying streams upstream of TUM 
#> Calculating furthest mainstem point downstream 
#> Querying streams downstream of TUM

# join upstream and downstream flowlines in nhd_list
flowlines = nhd_list$flowlines %>%
    rbind(nhd_list$dwn_flowlines)

```

```{r map-sites}
# load ggplot
library(ggplot2)

ggplot() +
  geom_sf(data = flowlines,
          aes(color = as.factor(StreamOrde),
              size = StreamOrde)) +
  scale_color_viridis_d(direction = -1,
                        option = "D",
                        name = "Stream\nOrder",
                        end = 0.8) +
  scale_size_continuous(range = c(0.2, 1.2),
                        guide = 'none') +
  geom_sf(data = nhd_list$basin,
          fill = NA,
          lwd = 2) +
  geom_sf(data = sites_sf,
          size = 4,
          color = "black") +
  ggrepel::geom_label_repel(
    data = sites_sf,
    aes(label = site_code, 
        geometry = geometry),
    size = 2,
    stat = "sf_coordinates",
    min.segment.length = 0,
    max.overlaps = 50
  ) +
  theme_bw() +
  theme(axis.title = element_blank())

```

```{r build-parent-child}
# build parent-child table
parent_child = buildParentChild(sites_sf,
                                flowlines)

```

```{r edit-parent-child}
# plot parent-child table
plotNodes(parent_child)

parent_child = editParentChild(parent_child,
                               fix_list = list(c(NA, "PES", "TUM"),
                                               c(NA, "LNF", "ICL"),
                                               c("PES", "ICL", "TUM")),
                               switch_parent_child = list(c("ICL", "TUM")))

# view corrected parent-child table
parent_child

```

```{r add-nodes}
# expand the parent_child table to include nodes
parent_child_nodes = addParentChildNodes(parent_child = parent_child,
                                         configuration = config)

# view expanded parent-child table
parent_child_nodes

# plot expanded parent-child table
plotNodes(parent_child_nodes)

```

```{r build-node-order, eval = F, echo = F}
# having an issue with both of these functions at the moment

node_paths = buildPaths(parent_child = parent_child)

# build path and order to each location
node_order <- buildNodeOrder(parent_child = parent_child_nodes)

```

# Compress Detections

```{r compress}
# compress observations
comp_obs = compress(raw_ptagis,
                    configuration = config)

# view compressed observations
head(comp_obs)

# compare number of directions
nrow(raw_ptagis)
nrow(comp_obs)

```

```{r add-direction}
# add direction based on parent-child table
comp_dir <- addDirection(compress_obs = comp_obs, 
                         parent_child = parent_child_nodes, 
                         direction = "u")

```

```{r filter-detections}
# add direction, and filter detections
comp_filter = filterDetections(compress_obs = comp_obs, 
                               parent_child = parent_child_nodes,
                               max_obs_date = "20180930")

comp_filter %>%
  select(tag_code:min_det, 
         direction,
         ends_with("keep_obs")) %>%
  filter(is.na(user_keep_obs)) %>%
  filter(tag_code == tag_code[1]) %>%
  kable() %>%
  kable_styling(full_width = T,
                bootstrap_options = "striped")

```

```{r auto-keep}
# after double checking PITcleanr calls filter out the final dataset for further analysis 
comp_final <- comp_filter %>%
  filter(auto_keep_obs)
```

```{r summarise-dets}
node_tags <- comp_final %>%
  group_by(node) %>%
  summarise(n_tags = n_distinct(tag_code))
```

```{r est-eff}
node_eff <- estNodeEff(comp_final, node_order = node_order)
```

```{r plot-est-tags}
# plot tags on a map
```

```{r config}
# the pre-built configuration file
configuration <- system.file("extdata", 
                             "TUM_configuration.csv", 
                             package = "PITcleanr",
                             mustWork = TRUE) |> 
  read_csv(show_col_types = F)

# the pre-built parent-child table
parent_child <- system.file("extdata", 
                            "TUM_parent_child.csv", 
                            package = "PITcleanr",
                            mustWork = TRUE) |> 
  read_csv(show_col_types = F)


```

